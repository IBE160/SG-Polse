Logistic Regression
1. 	What is Logistic Regression?
Logistic Regression is a machine learning algorithm used to predict categories â€” especially
yes/no, true/false, or 1/0 type outcomes.
It answers questions like:
â€¢ 	Will a student pass or fail an exam?
â€¢ 	Will a customer buy or not buy a product?
â€¢ 	Is an email spam or not spam?
So, instead of predicting a number (like in Linear Regression), Logistic Regression predicts a
probability â€” and then decides a class (0 or 1) based on that.
2. 	The â€œRegressionâ€ Part
Even though the name says regression, itâ€™s actually used for classification problems.
Hereâ€™s what happens:
It first fits a linear equation like in Linear Regression:
Then it passes that value (z) through a sigmoid function to turn it into a probability between 0
and 1.
3. 	The Sigmoid Function
The sigmoid (or logistic) function looks like this:
where
e is the base of the natural logarithm (~2.718),
z is the input value
It converts any number into a value between 0 and 1.

-- 1 of 6 --

Key Properties:
â€¢ 	Output range: (0, 1)â†’ This makes it useful for converting any real number into a
probability-like value. Shape: S-shaped (smooth and continuous).
â€¢ 	Center: At z =0, the output is 0.5 â†’ This is the point of symmetry.
Ã That means, for the sigmoid (logistic function)
Ã When z is very large â†’ ğ‘’âˆ’ğ‘§ becomes very small â†’ ğœ(
ğ‘§)â‰ˆ 1
Ã When z is very negative â†’ ğ‘’âˆ’ğ‘§ becomes very large â†’ ğœ(ğ‘§)â‰ˆ 0
Â´
So it squashes all inputs into the interval (0, 1).
Hereâ€™s the graph of the logistic (sigmoid) function â€” notice how it smoothly transitions from
0 to 1.
When z is very negative, Ïƒ(z) â†’ 0
When z is very positive, Ïƒ(z) â†’ 1
At z = 0, Ïƒ(z) = 0.5 (the decision threshold often used in classification)
4. Decision Boundary
After getting the probability, we choose a threshold (usually 0.5):
If probability â‰¥ 0.5 â†’ predict 1
If probability < 0.5 â†’ predict 0

-- 2 of 6 --

Example:
â€¢ 	If probability of â€œcustomer buyingâ€ = 0.8 â†’ predict Yes
â€¢ 	If probability = 0.3 â†’ predict No
5. Example in Simple Terms
Letâ€™s say we want to predict if a person will buy a car based on income.
Income ($) 	Bought Car
20,000 	No (0)
50,000 	Yes (1)
70,000 	Yes (1)
Logistic regression finds a line that best separates â€œYesâ€ and â€œNo,â€ then uses the sigmoid
curve to output probabilities like:
Income = 30,000 â†’ 0.2 (No)
Income = 60,000 â†’ 0.85 (Yes)
Logistic regression is used for classification tasks where the outcome is binary. It predicts the
probability of an event occurring by fitting data to a logistic curve.

-- 3 of 6 --

Comparison: Linear vs Logistic Regression
Feature 	Linear Regression 	Logistic Regression
Type of Outcome Continuous 	Binary/Categorical
Equation Form 	Linear (e.g., y=mx+b)
Logistic/Sigmoid (e.g., probability
output)
Use Case
Examples
Predicting salary based on
experience 	Predicting if an email is spam or not
Output 	Numeric prediction 	Probability of class membership
Both linear and logistic regression are foundational techniques in machine learning, with
linear regression suited for continuous predictions and logistic regression ideal for binary
classification tasks.
MASTER STEPS: LOGISTIC REGRESSION
Steps with explanations for creating a logistic regression model
To train a model using logistic regression in Python, you can follow these basic steps. This
example uses the scikit-learn library, which is widely used for machine learning tasks:
1. 	Import Necessary Libraries:
python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
2. 	Load and Prepare the Data:
Load your dataset into a Pandas DataFrame. For this example, let's assume you have a CSV
file:
python
data = pd.read_csv('your_dataset.csv')
3. 	Select Features and Target Variable:

-- 4 of 6 --

Identify the independent variables (features) and the dependent variable (target) you want to
predict.
python
X = data[['feature1', 'feature2', 'feature3']] # Replace with your actual feature names
y = data['target'] # Replace with your actual target variable name
4. 	Split the Data into Training and Test Sets:
Divide the data into training and test sets to evaluate the model's performance.
python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
5. 	Initialize and Train the Logistic Regression Model:
Create an instance of the LogisticRegression class and fit it to the training data.
python
model = LogisticRegression()
model.fit(X_train, y_train)
6. 	Make Predictions:
Use the trained model to make predictions on the test set.
python
y_pred = model.predict(X_test)
7. 	Evaluate the Model:
Assess the model's performance using metrics such as accuracy, confusion matrix, and
classification report.
python
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(conf_matrix)
class_report = classification_report(y_test, y_pred)
print('Classification Report:')
print(class_report)
Ã These steps provide a basic workflow for implementing logistic regression in Python
using scikit-learn.

-- 5 of 6 --

Ã You can adjust feature selection, data preprocessing, and evaluation metrics based on
your specific dataset and requirements.

-- 6 of 6 --

